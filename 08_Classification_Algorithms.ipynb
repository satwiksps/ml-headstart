{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8a65fa1a",
      "metadata": {
        "id": "8a65fa1a"
      },
      "source": [
        "# Classification Algorithms\n",
        "We test multiple machine learning models to compare their raw performance **before hyperparameter tuning**. This is a crucial first step in model selection."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1907ff0",
      "metadata": {
        "id": "a1907ff0"
      },
      "source": [
        "We will use the Pima Indians Diabetes dataset, which is commonly used for binary classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "a12b9ce9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a12b9ce9",
        "outputId": "c0e1b408-5865-4e17-94cb-138ef2c12b1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X1: (768, 8)\n",
            "Shape of Y1: (768,)\n"
          ]
        }
      ],
      "source": [
        "from pandas import read_csv\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/erojaso/MLMasteryEndToEnd/master/data/pima-indians-diabetes.data.csv'\n",
        "column_names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "data = read_csv(url, names=column_names)\n",
        "\n",
        "array = data.values\n",
        "X1 = array[:, 0:8]\n",
        "Y1 = array[:, 8]\n",
        "\n",
        "print(\"Shape of X1:\", X1.shape)\n",
        "print(\"Shape of Y1:\", Y1.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54ad9dfe",
      "metadata": {
        "id": "54ad9dfe"
      },
      "source": [
        "### Evaluation Strategy\n",
        "We use **10-Fold Cross-Validation** to evaluate model performance. This ensures reliable results and avoids overfitting to a particular data split."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34fb952a",
      "metadata": {
        "id": "34fb952a"
      },
      "source": [
        "### Logistic Regression\n",
        "A linear model often used for binary classification. It outputs probabilities and is interpretable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "f5011ab1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5011ab1",
        "outputId": "d9ec2a93-20b1-40c2-f840-49e07cf3be0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy: 0.770\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "kfold = KFold(n_splits=10)\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "results = cross_val_score(model, X1, Y1, cv=kfold)\n",
        "print(\"Logistic Regression Accuracy: %.3f\" % results.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6d2214a",
      "metadata": {
        "id": "e6d2214a"
      },
      "source": [
        "### Linear Discriminant Analysis (LDA)\n",
        "LDA is another linear classifier that works well when data is normally distributed and features are independent.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "e490bd04",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e490bd04",
        "outputId": "082cb133-b162-4b05-8bdf-02c5da98884a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LDA Accuracy: 0.773\n"
          ]
        }
      ],
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "\n",
        "model = LinearDiscriminantAnalysis()\n",
        "results = cross_val_score(model, X1, Y1, cv=kfold)\n",
        "print(\"LDA Accuracy: %.3f\" % results.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bf644b7",
      "metadata": {
        "id": "8bf644b7"
      },
      "source": [
        "### K-Nearest Neighbors (KNN)\n",
        "A non-parametric method. KNN makes predictions based on closest neighbors in training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "2ab013c7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ab013c7",
        "outputId": "6ff860c9-e8b2-4f6c-d6bb-edb4f74b95c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Accuracy: 0.727\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "model = KNeighborsClassifier()\n",
        "results = cross_val_score(model, X1, Y1, cv=kfold)\n",
        "print(\"KNN Accuracy: %.3f\" % results.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca4b64a7",
      "metadata": {
        "id": "ca4b64a7"
      },
      "source": [
        "### Naive Bayes\n",
        "Naive Bayes uses Bayes Theorem and assumes all features are independent. Itâ€™s extremely fast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "ff491fa5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff491fa5",
        "outputId": "b9c6f335-c6de-4e48-92d8-2e361b00c716"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Accuracy: 0.755\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "model = GaussianNB()\n",
        "results = cross_val_score(model, X1, Y1, cv=kfold)\n",
        "print(\"Naive Bayes Accuracy: %.3f\" % results.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edff2555",
      "metadata": {
        "id": "edff2555"
      },
      "source": [
        "### Classification and Regression Trees (CART)\n",
        "A decision-tree-based model that splits features using information gain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "ebb1b520",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebb1b520",
        "outputId": "8df86a2d-1712-4547-dc62-f17340c0f194"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Accuracy: 0.706\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "model = DecisionTreeClassifier()\n",
        "results = cross_val_score(model, X1, Y1, cv=kfold)\n",
        "print(\"Decision Tree Accuracy: %.3f\" % results.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e614386",
      "metadata": {
        "id": "5e614386"
      },
      "source": [
        "### Support Vector Machines (SVM)\n",
        "SVM finds a hyperplane that best separates the classes. Can work for both linear and non-linear data depending on the kernel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "fc910b71",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc910b71",
        "outputId": "4149f146-f13c-4a1f-d024-53c9cad59414"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 0.760\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "model = SVC()\n",
        "results = cross_val_score(model, X1, Y1, cv=kfold)\n",
        "print(\"SVM Accuracy: %.3f\" % results.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Model                  | Accuracy (mean of 10 folds) |\n",
        "|------------------------|-----------------------------|\n",
        "| Logistic Regression    | 0.770                        |\n",
        "| LDA                    | 0.773                        |\n",
        "| K-Nearest Neighbors    | 0.727                        |\n",
        "| Naive Bayes            | 0.755                        |\n",
        "| Decision Tree (CART)   | 0.703                        |\n",
        "| SVM                    | 0.760                        |\n"
      ],
      "metadata": {
        "id": "bucplMbq83ms"
      },
      "id": "bucplMbq83ms"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}