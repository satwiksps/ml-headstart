{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Standardization + LDA Pipeline\n",
        "\n",
        "In this approach, we use a `Pipeline` to first **standardize the dataset** using `StandardScaler` and then apply **Linear Discriminant Analysis (LDA)**.\n",
        "\n",
        "### Why this approach?\n",
        "- **StandardScaler** brings all input features to the same scale, improving model performance.\n",
        "- **LDA** is both a classifier and a dimensionality reduction technique that projects data in directions that maximize class separability.\n",
        "\n",
        "This pipeline helps us build a clean and reproducible machine learning process.\n"
      ],
      "metadata": {
        "id": "gxiCAcA7D3l2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and split the dataset\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/erojaso/MLMasteryEndToEnd/master/data/pima-indians-diabetes.data.csv'\n",
        "column_names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "data = read_csv(url, names=column_names)\n",
        "array = data.values\n",
        "X = array[:, 0:8]\n",
        "Y = array[:, 8]\n",
        "\n",
        "# Define the pipeline\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('lda', LinearDiscriminantAnalysis()))\n",
        "model = Pipeline(estimators)\n",
        "\n",
        "# Evaluate the pipeline using 10-fold cross-validation\n",
        "kfold = KFold(n_splits=10)\n",
        "results = cross_val_score(model, X, Y, cv=kfold)\n",
        "print(\"LDA Pipeline Mean Accuracy:\", results.mean())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwMDsFI2EBaG",
        "outputId": "773a191e-5805-4131-f716-24b1feadbb4a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LDA Pipeline Mean Accuracy: 0.773462064251538\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Union: PCA + SelectKBest + Logistic Regression\n",
        "\n",
        "In this pipeline, we combine **two feature selection techniques** using `FeatureUnion`:\n",
        "- **PCA (Principal Component Analysis):** A linear technique that projects data into a lower-dimensional space capturing maximum variance.\n",
        "- **SelectKBest:** A statistical feature selector that picks top `k` features based on univariate tests.\n",
        "\n",
        "Then we pass the combined features into a **Logistic Regression** classifier.\n",
        "\n",
        "### Why this is useful:\n",
        "- Different feature selection techniques capture different aspects of the data.\n",
        "- **FeatureUnion** lets us merge their outputs into one final dataset.\n",
        "- The combined model may offer better generalization than using either PCA or SelectKBest alone.\n"
      ],
      "metadata": {
        "id": "CXMwTF7qEEEh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import FeatureUnion\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "\n",
        "# Define FeatureUnion with PCA and SelectKBest\n",
        "features = []\n",
        "features.append(('pca', PCA(n_components=3)))\n",
        "features.append(('select_best', SelectKBest(k=6)))\n",
        "feature_union = FeatureUnion(features)\n",
        "\n",
        "# Create pipeline with feature union and logistic regression\n",
        "estimators = []\n",
        "estimators.append(('feature_union', feature_union))\n",
        "estimators.append(('logistic', LogisticRegression(solver='liblinear')))\n",
        "model = Pipeline(estimators)\n",
        "\n",
        "# Evaluate the pipeline\n",
        "kfold = KFold(n_splits=10)\n",
        "results = cross_val_score(model, X, Y, cv=kfold)\n",
        "print(\"FeatureUnion Pipeline Mean Accuracy:\", results.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLW3zYyoECZO",
        "outputId": "1c36d799-5526-4535-a602-7ca1fd29c073"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FeatureUnion Pipeline Mean Accuracy: 0.7760423786739576\n"
          ]
        }
      ]
    }
  ]
}